{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import imageio\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Encryption\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed to get the same output each time we run the code\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data import\n",
    "def rgb2grey(rgb):\n",
    "    return np.dot(rgb[..., :3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s= r'D:/gregg_data/'\n",
    "s_len = len(s)\n",
    "\n",
    "#collecting data from all images\n",
    "images=[]\n",
    "W= []\n",
    "H= []\n",
    "label=[]\n",
    "\n",
    "#Read image data\n",
    "for file in glob.glob(r\"D:\\gregg_data\\*.png\"):\n",
    "    f=imageio.imread(file)\n",
    "    H.append(f.shape[0])\n",
    "    W.append(f.shape[1])\n",
    "    g=rgb2grey(f)\n",
    "    images.append(g)\n",
    "    l=file[s_len:-4].lower()\n",
    "    label.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "214\n"
     ]
    }
   ],
   "source": [
    "#calculating the max height and width among all the images\n",
    "max_H = np.max(H)\n",
    "max_W = np.max(W)\n",
    "\n",
    "print(max_H)\n",
    "print(max_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding zeros to translate images to same size\n",
    "def appendzeros(img,h,w):\n",
    "    result = np.zeros(shape=(max_H,max_W,1))\n",
    "    img.shape=(h,w,1)\n",
    "    result[:h,:w,:] = img\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the data into train, validation and test set\n",
    "X_train = []\n",
    "X_test = []\n",
    "X_dev = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "Y_dev = []\n",
    "\n",
    "for i in range(len(images)):\n",
    "    img=appendzeros(images[i],H[i],W[i])\n",
    "    if i % 20 == 0:\n",
    "        X_dev.append(img)\n",
    "        Y_dev.append(label[i])\n",
    "    elif i % 20 == 1:\n",
    "        X_test.append(img)\n",
    "        Y_test.append(label[i])\n",
    "    else:\n",
    "        X_train.append(img)\n",
    "        Y_train.append(label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15709\n",
      "15709\n",
      "14137\n",
      "786\n",
      "786\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(len(label))\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translation dictionary \n",
    "alpha={\n",
    "    'a':0,\n",
    "    'b':1,\n",
    "    'c':2,\n",
    "    'd':3,\n",
    "    'e':4,\n",
    "    'f':5,\n",
    "    'g':6,\n",
    "    'h':7,\n",
    "    'i':8,\n",
    "    'j':9,\n",
    "    'k':10,\n",
    "    'l':11,\n",
    "    'm':12,\n",
    "    'n':13,\n",
    "    'o':14,\n",
    "    'p':15,\n",
    "    'q':16,\n",
    "    'r':17,\n",
    "    's':18,\n",
    "    't':19,\n",
    "    'u':20,\n",
    "    'v':21,\n",
    "    'w':22,\n",
    "    'x':23,\n",
    "    'y':24,\n",
    "    'z':25,\n",
    "    '#':26, #<PAD>\n",
    "    '+':27  #<GO>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#personalized one hot vector function\n",
    "def one_hot(A):\n",
    "    Y=[]\n",
    "    for t in A:\n",
    "        T=np.zeros(shape=(2,26))\n",
    "        for i in range(26):\n",
    "            if t[i]==1:\n",
    "                T[1][i]=1.0\n",
    "            else:\n",
    "                T[0][i]=1.0\n",
    "        Y.append(T)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior probabilities in training data\n",
    "def mplusmat():\n",
    "    m= np.zeros(shape=(26,2))\n",
    "    total_characters=0\n",
    "\n",
    "    for l in Y_train:\n",
    "        for i in range(len(l)):\n",
    "            if l[i].isalpha():\n",
    "                m[alpha[l[i]]][0]= m[alpha[l[i]]][0] + 1\n",
    "                total_characters=total_characters+1\n",
    "\n",
    "    for i in range(m.shape[0]):\n",
    "        m[i][0]=m[i][0]/total_characters\n",
    "        m[i][1]=1-m[i][0]\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translates the presence of characters into one vector of 26\n",
    "def label_translate(t):\n",
    "    t_label=np.zeros(shape=(26),dtype=int)\n",
    "    for i in range(0,26):\n",
    "        if i in t:\n",
    "            t_label[i]=1\n",
    "    return t_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translates all the characters in range 0-25\n",
    "def alpha_translate(label):\n",
    "    t=[]\n",
    "    l=(list(label))\n",
    "    for i in range(0,len(l)):\n",
    "        if l[i].isalpha():\n",
    "            t.append(alpha[l[i]])\n",
    "    return label_translate(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending all the translated labels\n",
    "def datafilter_alphabet():\n",
    "    tag_train=list()\n",
    "    tag_dev=list()\n",
    "    tag_test=list()\n",
    "        \n",
    "    for label in Y_train:\n",
    "        tag_train.append(alpha_translate(label))\n",
    "        \n",
    "    for label in Y_dev:\n",
    "        tag_dev.append(alpha_translate(label))\n",
    "            \n",
    "    for label in Y_test:\n",
    "        tag_test.append(alpha_translate(label))\n",
    "           \n",
    "    return np.asarray(tag_train),np.asarray(tag_dev),np.asarray(tag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squahing function to bring the output values into the range of 0 and 1\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    squared_norm = tf.reduce_mean(tf.square(s), axis=axis, keep_dims=True)\n",
    "    sq_norm_vec = tf.sqrt(squared_norm + epsilon)\n",
    "    squash_factor = squared_norm / (1. + squared_norm)\n",
    "    unit_vector = s / sq_norm_vec\n",
    "    return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#routing algorithm\n",
    "def routing(routing_iterations):\n",
    "    #initial logit set to zero; b_i,j <- 0\n",
    "    b_ij = tf.zeros([batch_size, primary_caps, alphacaps, alphacaps_label, 1, 1], dtype=np.float32, name=\"b_ij\")\n",
    "    for i in range(routing_iterations):\n",
    "        #c_i <- softmax(b_i,j)\n",
    "        c_i = tf.nn.softmax(b_ij, dim=2, name=\"c_i\")\n",
    "        #s_j <- sum_i(c_i,j* sec_caps_predicted)\n",
    "        s = tf.multiply(c_i, sec_caps_predicted, name=\"s\")\n",
    "        s_j = tf.reduce_sum(s, axis=1, keep_dims=True, name=\"s_j\")\n",
    "        #v_j <- squash(s_j)\n",
    "        v = squash(s_j, axis=-2, name=\"v\")\n",
    "        #duplicate v by caps1\n",
    "        v_j = tf.tile(v, [1, primary_caps, 1, 1, 1, 1], name=\"v_j\")\n",
    "        #agreement\n",
    "        agreement = tf.matmul(sec_caps_predicted, v_j, transpose_a=True, name=\"agreement\")\n",
    "        #update b_ij\n",
    "        b_ij = tf.add(b_ij, agreement)\n",
    "        #print(\"routing layer\",i+1,\"\\n\")\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcutaing norm of a vector\n",
    "def norm_vec(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    squared_norm_1 = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=keep_dims)\n",
    "    print(s)\n",
    "    return tf.sqrt(squared_norm_1 + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning hyperparameters\n",
    "n_epochs = 6\n",
    "n_iterations_per_epoch = 157\n",
    "b_size=15\n",
    "n_iter_val_test = 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'X:0' shape=(?, 131, 214, 1) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#placeholder for input pixels\n",
    "X=tf.placeholder(shape=[None,max_H,max_W, 1], dtype=tf.float32, name=\"X\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of capsules grids\n",
    "caps_grid=32\n",
    "#number of capsules\n",
    "primary_caps=caps_grid * 7 * 12\n",
    "#number of dimensions\n",
    "primary_caps_dims=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of convolution\n",
    "conv1_parameters = {\n",
    "    \"filters\": 32,\n",
    "    \"kernel_size\": 3,\n",
    "    \"strides\": 1,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu,\n",
    "}\n",
    "conv2_parameters = {\n",
    "    \"filters\": 64,\n",
    "    \"kernel_size\": 3,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "conv3_parameters = {\n",
    "    \"filters\": 128,\n",
    "    \"kernel_size\": 3,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "conv4_parameters = {\n",
    "    \"filters\": 256, \n",
    "    \"kernel_size\": 3,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}\n",
    "conv5_parameters = {\n",
    "    \"filters\": caps_grid * primary_caps_dims, \n",
    "    \"kernel_size\": 3,\n",
    "    \"strides\": 2,\n",
    "    \"padding\": \"valid\",\n",
    "    \"activation\": tf.nn.relu\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use five convolutional layers, each layer except for the the last ones is followed by a batch normalization function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv1/Relu:0\", shape=(?, 129, 212, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv1 = tf.layers.conv2d(X, name=\"conv1\", **conv1_parameters)\n",
    "print (conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batchnorm/add_1:0\", shape=(?, 129, 212, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mean1, var1 = tf.nn.moments(conv1,[0])\n",
    "scale1 = tf.Variable(tf.ones([32]))\n",
    "beta1 = tf.Variable(tf.zeros([32]))\n",
    "BN1 = tf.nn.batch_normalization(conv1,mean1,var1,beta1,scale1,epsilon)\n",
    "print(BN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2/Relu:0\", shape=(?, 64, 105, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv2 = tf.layers.conv2d(BN1, name=\"conv2\", **conv2_parameters)\n",
    "print (conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batchnorm_1/add_1:0\", shape=(?, 64, 105, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mean2, var2 = tf.nn.moments(conv2,[0])\n",
    "scale2 = tf.Variable(tf.ones([64]))\n",
    "beta2 = tf.Variable(tf.zeros([64]))\n",
    "BN2 = tf.nn.batch_normalization(conv2,mean2,var2,beta2,scale2,epsilon)\n",
    "print(BN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv3/Relu:0\", shape=(?, 31, 52, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv3 = tf.layers.conv2d(BN2, name=\"conv3\", **conv3_parameters)\n",
    "print (conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batchnorm_2/add_1:0\", shape=(?, 31, 52, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mean3, var3 = tf.nn.moments(conv3,[0])\n",
    "scale3 = tf.Variable(tf.ones([128]))\n",
    "beta3 = tf.Variable(tf.zeros([128]))\n",
    "BN3 = tf.nn.batch_normalization(conv3,mean3,var3,beta3,scale3,epsilon)\n",
    "print(BN3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv3/Relu:0\", shape=(?, 31, 52, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv4 = tf.layers.conv2d(BN3, name=\"conv4\", **conv4_parameters)\n",
    "print (conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"batchnorm_3/add_1:0\", shape=(?, 15, 25, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mean4, var4 = tf.nn.moments(conv4,[0])\n",
    "scale4 = tf.Variable(tf.ones([256]))\n",
    "beta4 = tf.Variable(tf.zeros([256]))\n",
    "BN4 = tf.nn.batch_normalization(conv4,mean4,var4,beta4,scale4,epsilon)\n",
    "print(BN4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv5/Relu:0\", shape=(?, 7, 12, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv5 = tf.layers.conv2d(BN4, name=\"conv5\", **conv5_parameters)\n",
    "print (conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"primary_caps_reshaped:0\", shape=(?, 2688, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#reshape to get 8D output vectors from primary capsules\n",
    "primary_caps_reshaped = tf.reshape(conv5, [-1, primary_caps, primary_caps_dims],name=\"primary_caps_reshaped\")\n",
    "print(primary_caps_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-b90b3b7c284f>:3: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Tensor(\"mul:0\", shape=(?, 2688, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#squashing\n",
    "primary_caps_output = squash(primary_caps_reshaped, name=\"primary_caps_output\")\n",
    "print (primary_caps_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alphabet Capsule\n",
    "alphacaps = 26\n",
    "alphacaps_label = 2\n",
    "alphacaps_dims = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2688, 26, 2, 16, 8)\n"
     ]
    }
   ],
   "source": [
    "init_sigma = 0.01\n",
    "\n",
    "#initialize weight matrix for transformation\n",
    "W_random = tf.random_normal(\n",
    "    shape=(1, primary_caps, alphacaps, alphacaps_label, alphacaps_dims, primary_caps_dims),name=\"W_random\",\n",
    "    stddev=init_sigma, dtype=tf.float32)\n",
    "W = tf.Variable(W_random, name=\"W\")\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'W_tiled:0' shape=(?, 2688, 26, 2, 16, 8) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create weight matrix for entire batch size\n",
    "batch_size = tf.shape(X)[0]\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "W_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"prim_caps_out_exp:0\", shape=(?, 2688, 8, 1), dtype=float32)\n",
      "Tensor(\"prim_caps_out_tile:0\", shape=(?, 2688, 1, 8, 1), dtype=float32)\n",
      "Tensor(\"prim_caps_out_tile2:0\", shape=(?, 2688, 1, 1, 8, 1), dtype=float32)\n",
      "Tensor(\"prim_caps_out_tile3:0\", shape=(?, 2688, 26, 2, 8, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#preparing output for multiplication\n",
    "prim_caps_out_exp = tf.expand_dims(primary_caps_output, -1, name=\"prim_caps_out_exp\")\n",
    "prim_caps_out_tile = tf.expand_dims(prim_caps_out_exp, 2, name=\"prim_caps_out_tile\")\n",
    "prim_caps_out_tile2 = tf.expand_dims(prim_caps_out_tile, 3, name=\"prim_caps_out_tile2\")\n",
    "prim_caps_out_tile3 = tf.tile(prim_caps_out_tile2, [1, 1, alphacaps, alphacaps_label, 1, 1], name=\"prim_caps_out_tile3\")\n",
    "print(prim_caps_out_exp)\n",
    "print(prim_caps_out_tile)\n",
    "print(prim_caps_out_tile2)\n",
    "print(prim_caps_out_tile3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformation of 8D vectors to 16D vectors\n",
    "sec_caps_predicted = tf.matmul(W_tiled, prim_caps_out_tile3, name=\"sec_caps_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sec_caps_predicted:0' shape=(?, 2688, 26, 2, 16, 1) dtype=float32>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(16X8) matmul by (8X1) => (16X1)\n",
    "sec_caps_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-304f8450dcf9>:7: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "WARNING:tensorflow:From <ipython-input-18-304f8450dcf9>:10: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "#output from secondary capsules via roouting\n",
    "sec_caps_output = routing(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul_6:0\", shape=(?, 1, 26, 2, 16, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sqrt_7:0' shape=(?, 1, 26, 2, 1) dtype=float32>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probabilities of each label class\n",
    "y_proba = norm_vec(sec_caps_output, axis=-2, name=\"y_proba\")\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_proba_max:0' shape=(?, 1, 26, 1) dtype=float32>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_max=tf.reduce_max(y_proba, axis=3, name=\"y_proba_max\")\n",
    "y_proba_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_proba:0' shape=(?, 1, 26, 1) dtype=int64>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_argmax = tf.argmax(y_proba, axis=3, name=\"y_proba\")\n",
    "y_proba_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted vector\n",
    "y_pred = tf.squeeze(y_proba_argmax, axis=[1,3], name=\"y_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_pred:0' shape=(?, 26) dtype=int64>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y:0' shape=(?, 26) dtype=int64>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input vector\n",
    "y = tf.placeholder(shape=[None,26], dtype=tf.int64, name=\"y\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'T:0' shape=(?, 2, 26) dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one_hot representation of input vector\n",
    "T= tf.placeholder(shape=[None,2,26], dtype=tf.float32, name=\"T\")\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameters for loss function\n",
    "m_plus = mplusmat()\n",
    "m_minus = 1- m_plus\n",
    "lambda_ = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul_6:0\", shape=(?, 1, 26, 2, 16, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sqrt_8:0' shape=(?, 1, 26, 2, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_output_norm = norm_vec(sec_caps_output, axis=-2, keep_dims=True, name=\"sec_output_norm\")\n",
    "sec_output_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_out_norm_reshape= tf.reshape(sec_output_norm, shape=(-1, alphacaps, alphacaps_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"present_error:0\", shape=(?, 26, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "present_error = tf.square(tf.maximum(0., m_plus - sec_out_norm_reshape), name=\"present_error\")\n",
    "print(present_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"absent_error:0\", shape=(?, 26, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "absent_error = tf.square(tf.maximum(0., sec_out_norm_reshape- m_minus), name=\"absent_error\")\n",
    "print(absent_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'L:0' shape=(?, 26, 26) dtype=float32>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = tf.add(tf.matmul(present_error,T), lambda_ * tf.matmul(absent_error,(1.0 - T)), name=\"L\")\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'margin_loss:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loss\n",
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=2), name=\"margin_loss\")\n",
    "margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#existence prediction accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y, y_pred), tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(A,B,i,size):\n",
    "    x= (i-1)*size\n",
    "    y= (i)*size  \n",
    "            \n",
    "    x_batch= A[x:y]\n",
    "    y_batch= B[x:y]\n",
    "    y_vec= one_hot(y_batch)\n",
    "    \n",
    "    return x_batch,y_batch,y_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(margin_loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model  1 :  Loss: 3.97591\n",
      "Val accuracy: 43.0417%  Loss: 4.615107\n",
      "Evaluating the model  2 :  Loss: 4.06781\n",
      "Val accuracy: 57.8391%  Loss: 4.981878\n",
      "Evaluating the model  3 :  Loss: 3.91798\n",
      "Val accuracy: 37.0816%  Loss: 4.593509\n",
      "Evaluating the model  4 :  Loss: 3.93308\n",
      "Val accuracy: 63.4469%  Loss: 4.963714\n",
      "Evaluating the model  5 :  Loss: 3.92564\n",
      "Val accuracy: 43.1298%  Loss: 4.589741\n",
      "Evaluating the model  6 :  Loss: 4.17181\n",
      "Val accuracy: 34.1163%  Loss: 4.616359\n"
     ]
    }
   ],
   "source": [
    "#training the capsule network\n",
    "restore_checkpoint = True\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"./my_gregg_capsule_network26_labelvec_batchnorm4\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "\n",
    "    train_tag, dev_tag, test_tag = datafilter_alphabet()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "            train_X,train_Y,train_Y_vec=next_batch(X_train,train_tag,iteration,b_size)\n",
    "                        \n",
    "            _, loss_train = sess.run([training_op, margin_loss],feed_dict={X: train_X,y: train_Y, T: train_Y_vec})\n",
    "            print(\"\\rIteration: {}/{} {:.1f}%  Loss: {:.5f}\".format(iteration, n_iterations_per_epoch,\n",
    "                     iteration * 100 / n_iterations_per_epoch,loss_train), end=\"\")\n",
    "            \n",
    "        \n",
    "        dev_X,dev_Y,dev_Y_vec=next_batch(X_dev,dev_tag,epoch+1,n_iter_val_test)\n",
    "        loss_val, acc_val = sess.run([margin_loss, accuracy],feed_dict={X: dev_X, y: dev_Y, T: dev_Y_vec})\n",
    "        \n",
    "        print(\"\\rEvaluating the model \",epoch+1,\":\")\n",
    "        print(\"\\rVal accuracy: {:.4f}%  Loss: {:.6f}\".format(acc_val * 100, loss_val))\n",
    "\n",
    "        if loss_val < best_loss_val:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "            best_loss_val = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_gregg_capsule_network26_labelvec_batchnorm4\n",
      "Evaluating the model  1 :\n",
      "Val accuracy: 35.2613%  Loss: 4.531071\n",
      "Evaluating the model  2 :\n",
      "Val accuracy: 42.5426%  Loss: 5.210499\n",
      "Evaluating the model  3 :\n",
      "Val accuracy: 45.0969%  Loss: 4.867248\n",
      "Evaluating the model  4 :\n",
      "Val accuracy: 36.8174%  Loss: 4.619494\n",
      "Evaluating the model  5 :\n",
      "Val accuracy: 46.8585%  Loss: 4.853778\n",
      "Evaluating the model  6 :\n",
      "Val accuracy: 41.9260%  Loss: 4.457479\n",
      "Final test accuracy: 41.4171%  Loss: 4.756595\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "\n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        test_X,test_Y,test_Y_vec=next_batch(X_test,test_tag,epoch+1,n_iter_val_test)\n",
    "        loss_test, acc_test = sess.run([margin_loss, accuracy],feed_dict={X: test_X, y: test_Y, T: test_Y_vec})\n",
    "        \n",
    "        print(\"\\rEvaluating the model \",epoch+1,\":\")\n",
    "        print(\"\\rVal accuracy: {:.4f}%  Loss: {:.6f}\".format(acc_test * 100, loss_test))\n",
    "\n",
    "        loss_tests.append(loss_test)\n",
    "        acc_tests.append(acc_test)\n",
    "\n",
    "    loss_test = np.mean(loss_tests)\n",
    "    acc_test = np.mean(acc_tests)\n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(acc_test * 100, loss_test))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
